# ============================================================================
# GitHub Actions - AWS Deployment Pipeline
# ============================================================================
# Deploys API, Scraper and Frontend to AWS
# Triggers on push to main or manual dispatch
# ============================================================================

name: Deploy to AWS

on:
  push:
    branches:
      - main
    paths:
      - 'backend/**'
      - 'src/**'
      - 'docker/**'
      - 'infra/aws/**'
      - '.github/workflows/deploy-aws.yml'
  workflow_dispatch:
    inputs:
      deploy_api:
        description: 'Deploy API'
        required: true
        default: true
        type: boolean
      deploy_scraper:
        description: 'Deploy Scraper'
        required: true
        default: true
        type: boolean
      deploy_frontend:
        description: 'Deploy Frontend'
        required: true
        default: true
        type: boolean
      environment:
        description: 'Environment'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging

env:
  AWS_REGION: us-east-2
  ECR_REGISTRY: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.us-east-2.amazonaws.com
  ECS_CLUSTER: didin-production
  NODE_VERSION: '20'
  PYTHON_VERSION: '3.11'

jobs:
  # ============================================================================
  # Determine what to deploy
  # ============================================================================
  changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    outputs:
      api: ${{ steps.filter.outputs.api }}
      scraper: ${{ steps.filter.outputs.scraper }}
      frontend: ${{ steps.filter.outputs.frontend }}
      infra: ${{ steps.filter.outputs.infra }}
    steps:
      - uses: actions/checkout@v4

      - uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            api:
              - 'backend/api/**'
              - 'backend/shared/**'
              - 'backend/modules/**'
              - 'backend/requirements.txt'
              - 'docker/api.Dockerfile'
            scraper:
              - 'backend/scraper/**'
              - 'backend/workers/**'
              - 'backend/shared/**'
              - 'backend/requirements-scraper.txt'
              - 'docker/scraper.Dockerfile'
            frontend:
              - 'src/**'
              - 'public/**'
              - 'index.html'
              - 'package.json'
              - 'vite.config.ts'
              - 'tailwind.config.js'
            infra:
              - 'infra/aws/**'

  # ============================================================================
  # Run Tests
  # ============================================================================
  test-backend:
    name: Test Backend
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.api == 'true' || needs.changes.outputs.scraper == 'true' || github.event_name == 'workflow_dispatch'
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: test_didin
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        ports:
          - 5432:5432
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5
      
      redis:
        image: redis:7
        ports:
          - 6379:6379
        options: --health-cmd "redis-cli ping" --health-interval 10s --health-timeout 5s --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: backend/requirements.txt

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio httpx

      - name: Run tests
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_didin
          REDIS_URL: redis://localhost:6379
          JWT_SECRET_KEY: test-secret-key
          ENVIRONMENT: test
        run: |
          cd backend
          pytest tests/ -v --cov=api --cov=modules --cov-report=xml

      - name: Upload coverage
        uses: codecov/codecov-action@v4
        with:
          file: backend/coverage.xml
          flags: backend

  test-frontend:
    name: Test Frontend
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.frontend == 'true' || github.event_name == 'workflow_dispatch'

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Type check
        run: npm run type-check || true

      - name: Run tests
        run: npm run test:unit -- --coverage

      - name: Upload coverage
        uses: codecov/codecov-action@v4
        with:
          file: coverage/coverage-final.json
          flags: frontend

  # ============================================================================
  # Build and Push Docker Images
  # ============================================================================
  build-api:
    name: Build API Image
    runs-on: ubuntu-latest
    needs: [changes, test-backend]
    if: |
      always() &&
      (needs.test-backend.result == 'success' || needs.test-backend.result == 'skipped') &&
      (needs.changes.outputs.api == 'true' || github.event.inputs.deploy_api == 'true')
    
    outputs:
      image_tag: ${{ steps.build.outputs.image_tag }}

    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push API image
        id: build
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build \
            -f docker/api.Dockerfile \
            -t $ECR_REGISTRY/didin-api:$IMAGE_TAG \
            -t $ECR_REGISTRY/didin-api:latest \
            --build-arg ENVIRONMENT=production \
            .
          
          docker push $ECR_REGISTRY/didin-api:$IMAGE_TAG
          docker push $ECR_REGISTRY/didin-api:latest
          
          echo "image_tag=$IMAGE_TAG" >> $GITHUB_OUTPUT

  build-scraper:
    name: Build Scraper Image
    runs-on: ubuntu-latest
    needs: [changes, test-backend]
    if: |
      always() &&
      (needs.test-backend.result == 'success' || needs.test-backend.result == 'skipped') &&
      (needs.changes.outputs.scraper == 'true' || github.event.inputs.deploy_scraper == 'true')
    
    outputs:
      image_tag: ${{ steps.build.outputs.image_tag }}

    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push Scraper image
        id: build
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build \
            -f docker/scraper.Dockerfile \
            -t $ECR_REGISTRY/didin-scraper:$IMAGE_TAG \
            -t $ECR_REGISTRY/didin-scraper:latest \
            --build-arg ENVIRONMENT=production \
            .
          
          docker push $ECR_REGISTRY/didin-scraper:$IMAGE_TAG
          docker push $ECR_REGISTRY/didin-scraper:latest
          
          echo "image_tag=$IMAGE_TAG" >> $GITHUB_OUTPUT

  build-frontend:
    name: Build Frontend
    runs-on: ubuntu-latest
    needs: [changes, test-frontend]
    if: |
      always() &&
      (needs.test-frontend.result == 'success' || needs.test-frontend.result == 'skipped') &&
      (needs.changes.outputs.frontend == 'true' || github.event.inputs.deploy_frontend == 'true')

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build
        env:
          VITE_API_URL: ${{ secrets.VITE_API_URL }}
          VITE_MERCADOPAGO_PUBLIC_KEY: ${{ secrets.MERCADOPAGO_PUBLIC_KEY }}
        run: npm run build

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: frontend-build
          path: dist/
          retention-days: 1

  # ============================================================================
  # Deploy to AWS
  # ============================================================================
  deploy-api:
    name: Deploy API
    runs-on: ubuntu-latest
    needs: build-api
    if: needs.build-api.result == 'success'
    environment: production

    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Deploy to ECS
        run: |
          aws ecs update-service \
            --cluster $ECS_CLUSTER \
            --service didin-api \
            --force-new-deployment
          
          echo "Waiting for deployment to complete..."
          aws ecs wait services-stable \
            --cluster $ECS_CLUSTER \
            --services didin-api

      - name: Notify deployment
        if: always()
        run: |
          if [ "${{ job.status }}" == "success" ]; then
            echo "✅ API deployed successfully"
          else
            echo "❌ API deployment failed"
          fi

  deploy-scraper:
    name: Deploy Scraper
    runs-on: ubuntu-latest
    needs: build-scraper
    if: needs.build-scraper.result == 'success'
    environment: production

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Deploy to ECS
        run: |
          aws ecs update-service \
            --cluster $ECS_CLUSTER \
            --service didin-scraper \
            --force-new-deployment
          
          echo "Waiting for deployment to complete..."
          aws ecs wait services-stable \
            --cluster $ECS_CLUSTER \
            --services didin-scraper

  deploy-frontend:
    name: Deploy Frontend
    runs-on: ubuntu-latest
    needs: build-frontend
    if: needs.build-frontend.result == 'success'
    environment: production

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: frontend-build
          path: dist/

      - name: Deploy to S3
        run: |
          aws s3 sync dist/ s3://didin-production-frontend \
            --delete \
            --cache-control "public, max-age=31536000" \
            --exclude "index.html" \
            --exclude "*.json"
          
          # HTML and JSON files with no-cache
          aws s3 cp dist/index.html s3://didin-production-frontend/index.html \
            --cache-control "no-cache, no-store, must-revalidate"
          
          # Copy any JSON files without cache
          find dist -name "*.json" -exec aws s3 cp {} s3://didin-production-frontend/{} \
            --cache-control "no-cache" \;

      - name: Invalidate CloudFront cache
        run: |
          aws cloudfront create-invalidation \
            --distribution-id ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }} \
            --paths "/*"

  # ============================================================================
  # Run Database Migrations
  # ============================================================================
  migrate:
    name: Run Migrations
    runs-on: ubuntu-latest
    needs: deploy-api
    if: needs.deploy-api.result == 'success'
    environment: production

    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Run Alembic migrations
        run: |
          # Run migration as ECS task
          TASK_ARN=$(aws ecs run-task \
            --cluster $ECS_CLUSTER \
            --task-definition didin-api-migration \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={subnets=[${{ secrets.PRIVATE_SUBNET_IDS }}],securityGroups=[${{ secrets.ECS_SECURITY_GROUP_ID }}]}" \
            --overrides '{"containerOverrides":[{"name":"api","command":["alembic","upgrade","head"]}]}' \
            --query 'tasks[0].taskArn' \
            --output text)
          
          echo "Migration task started: $TASK_ARN"
          
          # Wait for task to complete
          aws ecs wait tasks-stopped \
            --cluster $ECS_CLUSTER \
            --tasks $TASK_ARN
          
          # Check exit code
          EXIT_CODE=$(aws ecs describe-tasks \
            --cluster $ECS_CLUSTER \
            --tasks $TASK_ARN \
            --query 'tasks[0].containers[0].exitCode' \
            --output text)
          
          if [ "$EXIT_CODE" != "0" ]; then
            echo "Migration failed with exit code $EXIT_CODE"
            exit 1
          fi
          
          echo "✅ Migrations completed successfully"

  # ============================================================================
  # Post-deployment Health Check
  # ============================================================================
  health-check:
    name: Health Check
    runs-on: ubuntu-latest
    needs: [deploy-api, deploy-frontend]
    if: always() && (needs.deploy-api.result == 'success' || needs.deploy-frontend.result == 'success')

    steps:
      - name: Check API health
        if: needs.deploy-api.result == 'success'
        run: |
          for i in {1..10}; do
            response=$(curl -s -o /dev/null -w "%{http_code}" https://api.didin.com.br/health)
            if [ "$response" == "200" ]; then
              echo "✅ API is healthy"
              exit 0
            fi
            echo "Attempt $i: API returned $response, retrying in 30s..."
            sleep 30
          done
          echo "❌ API health check failed"
          exit 1

      - name: Check Frontend
        if: needs.deploy-frontend.result == 'success'
        run: |
          response=$(curl -s -o /dev/null -w "%{http_code}" https://app.didin.com.br)
          if [ "$response" == "200" ]; then
            echo "✅ Frontend is accessible"
          else
            echo "⚠️ Frontend returned $response"
          fi

  # ============================================================================
  # Notify on completion
  # ============================================================================
  notify:
    name: Notify
    runs-on: ubuntu-latest
    needs: [deploy-api, deploy-scraper, deploy-frontend, health-check]
    if: always()

    steps:
      - name: Send Slack notification
        if: env.SLACK_WEBHOOK_URL != ''
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          API_STATUS="${{ needs.deploy-api.result }}"
          SCRAPER_STATUS="${{ needs.deploy-scraper.result }}"
          FRONTEND_STATUS="${{ needs.deploy-frontend.result }}"
          
          if [ "$API_STATUS" == "success" ] && [ "$FRONTEND_STATUS" == "success" ]; then
            COLOR="good"
            TITLE="✅ Deployment Successful"
          else
            COLOR="danger"
            TITLE="❌ Deployment Failed"
          fi
          
          curl -X POST -H 'Content-type: application/json' \
            --data "{
              \"attachments\": [{
                \"color\": \"$COLOR\",
                \"title\": \"$TITLE\",
                \"fields\": [
                  {\"title\": \"API\", \"value\": \"$API_STATUS\", \"short\": true},
                  {\"title\": \"Scraper\", \"value\": \"$SCRAPER_STATUS\", \"short\": true},
                  {\"title\": \"Frontend\", \"value\": \"$FRONTEND_STATUS\", \"short\": true},
                  {\"title\": \"Commit\", \"value\": \"${{ github.sha }}\", \"short\": true}
                ]
              }]
            }" \
            $SLACK_WEBHOOK_URL
